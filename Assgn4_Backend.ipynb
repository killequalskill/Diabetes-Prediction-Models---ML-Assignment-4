{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6014,
     "status": "ok",
     "timestamp": 1764070376980,
     "user": {
      "displayName": "PARTH AJIT DHAMALE",
      "userId": "11826448880231138314"
     },
     "user_tz": -330
    },
    "id": "P_lzBTgJv-3R",
    "outputId": "ae164fd9-bc9e-4a1c-9982-d6850a888ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Naive Bayes model from naive_bayes_model.pkl\n",
      "Loaded MLP model from mlp_model.pkl\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://172.16.42.113:8000\n",
      "Press CTRL+C to quit\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:09] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:09] \"POST /predict HTTP/1.1\" 201 -\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:11] \"POST /predict HTTP/1.1\" 201 -\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:16] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:16] \"POST /predict HTTP/1.1\" 201 -\n",
      "172.16.42.113 - - [27/Nov/2025 12:20:19] \"POST /predict HTTP/1.1\" 201 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from custom_mlp import CustomMLP_4_8_1\n",
    "\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "# Enable CORS\n",
    "CORS(app,resources={\"r/*\":{\"origins\":\"*\"}})\n",
    "\n",
    "@app.after_request\n",
    "def handle_cors(response):\n",
    "    response.headers[\"Access-Control-Allow-Headers\"]=\"Content-Type,Authorization\"\n",
    "    response.headers[\"Access-Control-Allow-Methods\"]=\"GET,POST,OPTIONS\"\n",
    "    response.headers['Access-Control-Allow-Origin']=\"*\"\n",
    "    return response\n",
    "# Load the trained models\n",
    "# Update these paths to where you saved your models\n",
    "NB_MODEL_PATH = \"naive_bayes_model.pkl\"\n",
    "MLP_MODEL_PATH = \"mlp_model.pkl\"\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    with open(NB_MODEL_PATH, 'rb') as f:\n",
    "        loaded_nb_model = pickle.load(f)\n",
    "    print(f\"Loaded Naive Bayes model from {NB_MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Naive Bayes model not found at {NB_MODEL_PATH}\")\n",
    "    loaded_nb_model = None\n",
    "\n",
    "\n",
    "\n",
    "#with open(MLP_MODEL_PATH, \"rb\") as f:\n",
    "   # loaded_mlp_model = pickle.load(f)\n",
    "\n",
    "try:\n",
    "    with open(MLP_MODEL_PATH, 'rb') as f:\n",
    "        loaded_mlp_model = pickle.load(f)\n",
    "    print(f\"Loaded MLP model from {MLP_MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: MLP model not found at {MLP_MODEL_PATH}\")\n",
    "    loaded_mlp_model = None\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    API endpoint to make predictions using either Naive Bayes or MLP model.\n",
    "\n",
    "    Expected JSON input:\n",
    "    {\n",
    "        \"age\": float,\n",
    "        \"glucose\": float,\n",
    "        \"insulin\": float,\n",
    "        \"bmi\": float,\n",
    "        \"model_type\": \"naive_bayes\" or \"mlp\" (default: \"naive_bayes\")\n",
    "    }\n",
    "\n",
    "    Returns:\n",
    "    {\n",
    "        \"diabetes_type\": 0 or 1,\n",
    "        \"model_used\": \"naive_bayes\" or \"mlp\",\n",
    "        \"confidence\": probability score (if available)\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "\n",
    "        # Get model type (default to naive_bayes)\n",
    "        model_type = data.get('model_type', 'naive_bayes').lower()\n",
    "\n",
    "        # Extract features\n",
    "        age = float(data['age'])\n",
    "        glucose = float(data['glucose'])\n",
    "        insulin = float(data['insulin'])\n",
    "        bmi = float(data['bmi'])\n",
    "\n",
    "        # Create input array\n",
    "        input_features = np.array([[age, glucose, insulin, bmi]])\n",
    "\n",
    "        # Make prediction based on model type\n",
    "        if model_type == 'naive_bayes':\n",
    "            if loaded_nb_model is None:\n",
    "                return jsonify({'error': 'Naive Bayes model not loaded'}), 500\n",
    "\n",
    "            prediction = loaded_nb_model.predict(input_features)\n",
    "            # Get probability for confidence\n",
    "            probabilities = loaded_nb_model.predict_proba(input_features)\n",
    "            confidence = float(np.max(probabilities))\n",
    "\n",
    "            return jsonify({\n",
    "                'diabetes_type': int(prediction[0]),\n",
    "                'model_used': 'naive_bayes',\n",
    "                'confidence': confidence\n",
    "            }),201\n",
    "\n",
    "        elif model_type == 'mlp':\n",
    "            if loaded_mlp_model is None:\n",
    "                return jsonify({'error': 'MLP model not loaded'}), 500\n",
    "            if not hasattr(loaded_mlp_model, 'predict'):\n",
    "                return jsonify({\n",
    "                    'error': 'Loaded MLP object does not implement predict(). '\n",
    "                     'It seems the class definition used at save-time is missing.'\n",
    "                    }), 500\n",
    "            prediction = loaded_mlp_model.predict(input_features)\n",
    "\n",
    "            return jsonify({\n",
    "                'diabetes_type': int(prediction[0]),\n",
    "                'model_used': 'mlp',\n",
    "                'confidence': None  # Custom MLP doesn't have predict_proba\n",
    "            }),201\n",
    "\n",
    "        else:\n",
    "            return jsonify({'error': f'Invalid model type: {model_type}. Use \"naive_bayes\" or \"mlp\"'}), 400\n",
    "\n",
    "    except KeyError as e:\n",
    "        return jsonify({'error': f'Missing required field: {str(e)}'}), 400\n",
    "    except ValueError as e:\n",
    "        return jsonify({'error': f'Invalid input values: {str(e)}'}), 400\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Prediction error: {str(e)}'}), 500\n",
    "\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'naive_bayes_loaded': loaded_nb_model is not None,\n",
    "        'mlp_loaded': loaded_mlp_model is not None\n",
    "    }),200\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    \"\"\"Home endpoint with API documentation\"\"\"\n",
    "    return jsonify({\n",
    "        'message': 'Diabetes Prediction API',\n",
    "        'endpoints': {\n",
    "            'POST /predict': 'Make a prediction',\n",
    "            'GET /health': 'Health check'\n",
    "        },\n",
    "        'example_request': {\n",
    "            'age': 45,\n",
    "            'glucose': 120,\n",
    "            'insulin': 45,\n",
    "            'bmi': 28.5,\n",
    "            'model_type': 'naive_bayes'\n",
    "        }\n",
    "    }),200\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0qJVeDL7pldPu0VciJYG0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
