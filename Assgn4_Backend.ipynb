{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6014,
     "status": "ok",
     "timestamp": 1764070376980,
     "user": {
      "displayName": "PARTH AJIT DHAMALE",
      "userId": "11826448880231138314"
     },
     "user_tz": -330
    },
    "id": "P_lzBTgJv-3R",
    "outputId": "ae164fd9-bc9e-4a1c-9982-d6850a888ddd"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from custom_mlp import CustomMLP_4_8_1\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "CORS(app,resources={\"r/*\":{\"origins\":\"*\"}})\n",
    "\n",
    "@app.after_request\n",
    "def handle_cors(response):\n",
    "    response.headers[\"Access-Control-Allow-Headers\"]=\"Content-Type,Authorization\"\n",
    "    response.headers[\"Access-Control-Allow-Methods\"]=\"GET,POST,OPTIONS\"\n",
    "    response.headers['Access-Control-Allow-Origin']=\"*\"\n",
    "    return response\n",
    "\n",
    "NB_MODEL_PATH = \"naive_bayes_model.pkl\"\n",
    "MLP_MODEL_PATH = \"mlp_model.pkl\"\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    with open(NB_MODEL_PATH, 'rb') as f:\n",
    "        loaded_nb_model = pickle.load(f)\n",
    "    print(f\"Loaded Naive Bayes model from {NB_MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Naive Bayes model not found at {NB_MODEL_PATH}\")\n",
    "    loaded_nb_model = None\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(MLP_MODEL_PATH, 'rb') as f:\n",
    "        loaded_mlp_model = pickle.load(f)\n",
    "    print(f\"Loaded MLP model from {MLP_MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: MLP model not found at {MLP_MODEL_PATH}\")\n",
    "    loaded_mlp_model = None\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "\n",
    "      \n",
    "        model_type = data.get('model_type', 'naive_bayes').lower()\n",
    "\n",
    "        \n",
    "        age = float(data['age'])\n",
    "        glucose = float(data['glucose'])\n",
    "        insulin = float(data['insulin'])\n",
    "        bmi = float(data['bmi'])\n",
    "\n",
    "        input_features = np.array([[age, glucose, insulin, bmi]])\n",
    "\n",
    "        \n",
    "        if model_type == 'naive_bayes':\n",
    "            if loaded_nb_model is None:\n",
    "                return jsonify({'error': 'Naive Bayes model not loaded'}), 500\n",
    "\n",
    "            prediction = loaded_nb_model.predict(input_features)\n",
    "            \n",
    "            probabilities = loaded_nb_model.predict_proba(input_features)\n",
    "            confidence = float(np.max(probabilities))\n",
    "\n",
    "            return jsonify({\n",
    "                'diabetes_type': int(prediction[0]),\n",
    "                'model_used': 'naive_bayes',\n",
    "                'confidence': confidence\n",
    "            }),201\n",
    "\n",
    "        elif model_type == 'mlp':\n",
    "            if loaded_mlp_model is None:\n",
    "                return jsonify({'error': 'MLP model not loaded'}), 500\n",
    "            \n",
    "            prediction = loaded_mlp_model.predict(input_features)\n",
    "\n",
    "            return jsonify({\n",
    "                'diabetes_type': int(prediction[0]),\n",
    "                'model_used': 'mlp',\n",
    "                'confidence': None  \n",
    "            }),201\n",
    "\n",
    "        else:\n",
    "            return jsonify({'error': f'Invalid model type: {model_type}. Use \"naive_bayes\" or \"mlp\"'}), 400\n",
    "\n",
    "    except KeyError as e:\n",
    "        return jsonify({'error': f'Missing required field: {str(e)}'}), 400\n",
    "    except ValueError as e:\n",
    "        return jsonify({'error': f'Invalid input values: {str(e)}'}), 400\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Prediction error: {str(e)}'}), 500\n",
    "\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'naive_bayes_loaded': loaded_nb_model is not None,\n",
    "        'mlp_loaded': loaded_mlp_model is not None\n",
    "    }),200\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return jsonify({\n",
    "        'message': 'Diabetes Prediction API',\n",
    "        'endpoints': {\n",
    "            'POST /predict': 'Make a prediction',\n",
    "            'GET /health': 'Health check'\n",
    "        },\n",
    "        'example_request': {\n",
    "            'age': 45,\n",
    "            'glucose': 120,\n",
    "            'insulin': 45,\n",
    "            'bmi': 28.5,\n",
    "            'model_type': 'naive_bayes'\n",
    "        }\n",
    "    }),200\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0qJVeDL7pldPu0VciJYG0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
